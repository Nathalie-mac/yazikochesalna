
variables:
  # Имя Docker Registry
  DOCKER_REGISTRY: registry.gitlab.com
  PROJECT_NAME: liza.antipa/yazikochesalna

stages:
  - build
  - package
  - deploy

.build-template: &build-template
  stage: build
  image: amazoncorretto:21-alpine
  script:
    - chmod +x ./gradlew
    - ./gradlew :$SERVICE_DIR:build -x test
  artifacts:
    paths:
      - "$SERVICE_DIR/build/libs/"

.build-buildah-template: &build-docker-template
  stage: package
  image: quay.io/buildah/stable:latest
  variables:
    XDG_RUNTIME_DIR: /tmp
  script:
    - cd "$SERVICE_DIR"
    - echo "Авторизация в Container Registry"
    - buildah login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY"
    - TAG_NAME=$(echo $CI_COMMIT_BRANCH | sed 's/\//./g')
    - IMAGE_PATH="$DOCKER_REGISTRY/$PROJECT_NAME/$DOCKER_IMAGE_NAME:$TAG_NAME"
    - echo "Образ $IMAGE_PATH"
    - echo "Сборка образа с Buildah"
    - buildah bud -t "$IMAGE_PATH" .
    - echo "Пуш образа в registry"
    - buildah push "$IMAGE_PATH"
    
# --- Определяем job для каждого сервиса --- #
build-authorization-service:
  <<: *build-template
  variables:
    SERVICE_DIR: "authorization-service"


build-frontend:
  stage: build
  image: node:20
  allow_failure: true
  script:
    # Расшифровываем SSH-ключ
    - mkdir -p ~/.ssh
    - echo "$FRONTEND_SSH" | base64 --decode > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - mkdir -p ~/.ssh
    - |
      cat <<EOT > ~/.ssh/config
      Host gitlab.com
        IdentityAgent none
        StrictHostKeyChecking no
        UserKnownHostsFile=/dev/null
      EOT

    # Клонируем фронтенд
    - rm -rf frontend || true
    - git clone git@gitlab.com:$FRONTEND_PROJECT.git frontend  -b Develop-volodya
    
    - cd frontend
    # Перемещаем нужную папку внутрь frontend
    - mv messenger-front/* .
    # Убираем временные файлы
    - rm -rf messenger-front
    # Замена всех localhost:порт на ваш домен
    - sed -i 's|http://localhost:808[01235]|https://xn--80ajfmhmdz6cwbs0al.xn--p1ai|g' $(find . -type f -name "*.ts" -o -name "*.js" -o -name "*.tsx" -o -name "*.jsx" -o -name "*.json")
    # Устанавливаем зависимости и собираем проект
    - npm ci
    - npm run build

  artifacts:
    paths:
      - frontend/dist/

# --- Определяем Docker сборку для каждого сервиса --- #

docker-frontend:
  <<: *build-docker-template
  variables:
    SERVICE_DIR: frontend
    DOCKER_IMAGE_NAME: frontend
  dependencies:
    - build-frontend
  rules:   
    - if: true
      when: on_success 
  allow_failure: true
  


docker-authorization-service:
  <<: *build-docker-template
  variables:
    SERVICE_DIR: "authorization-service"
    DOCKER_IMAGE_NAME: "authorization-service"
  dependencies:
    - build-authorization-service
    
### --- Деплой --- ###


deploy-kustomize:
  stage: deploy
  image:
    name: lachlanevenson/k8s-kubectl:latest
    entrypoint: [""]
  allow_failure: true
  script:
    # Проверка, что переменная установлена
    - |
      if [ -z "$KUBECONFIG_CONTENTS" ]; then
        echo "Ошибка: переменная KUBECONFIG_CONTENTS не установлена"
        exit 1
      fi

    # Переход в директорию с kustomization.yaml
    - cd k8s/overlays/dev
    # Проверяем путь к файлу
    - echo "Путь к encoded kubeconfig - $KUBECONFIG_CONTENTS"

    # Читаем содержимое и декодируем
    - mkdir -p ~/.kube
    - cat "$KUBECONFIG_CONTENTS" | base64 -d > ~/.kube/config
    - chmod 600 ~/.kube/config
    - export KUBECONFIG=~/.kube/config

    # Диагностические команды
    - kubectl version --client
    - kubectl config view
    - kubectl config current-context
    - kubectl config get-contexts
    - kubectl version
    
    # Проверяем текущий контекст kubectl
    - kubectl config current-context

    # Применяем манифесты с помощью kustomize
    - kubectl -n messenger get secret gitlab-regcred && kubectl -n messenger delete secret gitlab-regcred
    - kubectl -n messenger apply -k .
    # Принудительно обновляем образы
    - kubectl get deployments -n messenger -o name | xargs -I {} kubectl rollout restart {} -n messenger
    # Принудительно обновляем манифесты ingress
    - kubectl rollout restart deployment -n ingress-nginx ingress-nginx-controller
#  needs:
#    - package:service1